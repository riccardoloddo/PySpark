{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7b0a7375-4adb-49d6-be73-ca620cc791d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from datetime import datetime\n",
    "import os\n",
    "import re\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, DateType, IntegerType\n",
    "from pyspark.sql.functions import current_date, col, to_date, when, current_timestamp, monotonically_increasing_id, lit, upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dba1b1a8-60a8-4ae5-aae3-2e5c497d1e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------------+-----------+-------+----------+\n",
      "|               CF|             NOME|         DN|SALARIO|      DINS|\n",
      "+-----------------+-----------------+-----------+-------+----------+\n",
      "| RSSMRA85M01H501Z|      Mario Rossi| 1985-03-15|   2500|2025-09-25|\n",
      "| RSSMRA85M01H501Z|      Mario Rossi| 1985-03-15|  -2500|2025-09-25|\n",
      "| BNCLGU90B22F205X|     Luca Bianchi| 1990-07-22|   3200|2025-09-25|\n",
      "| VRDLCN80C15D612Y|    Claudia Verdi| 15/08/1980|   2800|2025-09-25|\n",
      "| NGRMRT75D10E345W|     Martina Neri| 1975-12-10|   3100|2025-09-25|\n",
      "| FBLGPP88A12H501V|    Filippo Baldi| 1988-01-12|   2700|2025-09-25|\n",
      "| DMRCNZ92E18F205U|   Daniele Moroni|1992-06-188|   3000|2025-09-25|\n",
      "|  SPRTMN7820G345T|Simone Sportiello| 1978-20-20|   -500|2025-09-25|\n",
      "| GRLFRN83B25H501S|    Giorgia Ferri| 1983-02-25|   2900|2025-09-25|\n",
      "| CNCLNZ87C30D612R|   Concetta Lanza| 30-06-1987|    fff|2025-09-25|\n",
      "| PPLGRD91D05E345Q|   Paolo Pugliese| 1991-05-05|   3400|2025-09-25|\n",
      "| LDDRCR99R14F205U|   Riccardo Loddo| 1999-14-04|   2000|2025-09-25|\n",
      "| LDDRCR99R14F205U|   Riccardo Pippo| 1999-04-14|    abc|2025-09-25|\n",
      "| NGRMRT75D10E345W| Ma3t1na Polgatti| 1975-10-10|   3100|2025-09-25|\n",
      "| NGRMRT75D10E345W|      Maria Santa| 1975-10-10|   3100|2025-09-25|\n",
      "|     NGRMRT75345W|     Maria Santa1| 1975-??-10|   3100|2025-09-25|\n",
      "|     NGRMRT75345W|     Maria Santa2| 1975-10-10|   -100|2025-09-25|\n",
      "|     NGRMRT75345W|     Maria Santa3| 1975-10-10|    200|2025-09-25|\n",
      "| ABCD1234EF567890|       Z0l0 Rossi| 1980-13-01|   1500|2025-09-25|\n",
      "|LMNOPQ12RST345678|  Giulia1 Bianchi| 1990-02-30|   2800|2025-09-25|\n",
      "+-----------------+-----------------+-----------+-------+----------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "# Creo SparkSession\n",
    "spark = SparkSession.builder.master(\"local[1]\").appName(\"FlussoDipendenti\").getOrCreate()\n",
    "\n",
    "# Definisco lo schema come stringhe inizialmente (come in SQL)\n",
    "# StructType = insieme di colonne (struttura della tabella)\n",
    "# StructField = definizione di una singola colonna, con nome, tipo e possibilit√† di avere valori null\n",
    "schema = StructType([\n",
    "    StructField(\"CF\", StringType(), True),\n",
    "    StructField(\"NOME\", StringType(), True),\n",
    "    StructField(\"DN\", StringType(), True),\n",
    "    StructField(\"SALARIO\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Leggo il CSV\n",
    "df_raw = spark.read.csv(\"Flusso.csv\",\n",
    "    header=True,                        # la prima riga del CSV contiene i nomi delle colonne\n",
    "    schema=schema                       # nomi colonne\n",
    ")\n",
    "\n",
    "# Aggiungo la colonna DINS con la data corrente\n",
    "df_raw = df_raw.withColumn(\"DINS\", current_date()) # oppure current_timestamp() per vedere data ed ora. \n",
    "df_raw.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f09ff45d-212a-4908-bd15-a13887b2c4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff08171-813a-431d-b29c-969b7deca061",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86007804-d227-4616-a464-171c11a233e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "186a3aa5-a4d1-477f-ac8b-d92b2d9bafc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nome del file di log\n",
    "log_file = 'tlog.csv'\n",
    "\n",
    "# Se il file non esiste, creo l'intestazione\n",
    "if not os.path.exists(log_file):\n",
    "    with open(log_file, mode='w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['IDRUN', 'IDTLOG', 'CALLER', 'TESTO', 'DINS'])\n",
    "\n",
    "# Variabile globale per IDTLOG\n",
    "idtlog_counter = 1\n",
    "\n",
    "def plog(caller, testo, idrun):\n",
    "    global idtlog_counter\n",
    "    with open(log_file, mode='a', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\n",
    "            idrun,\n",
    "            idtlog_counter,\n",
    "            caller.upper(),\n",
    "            testo.upper(),\n",
    "            datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        ])\n",
    "    idtlog_counter += 1\n",
    "\n",
    "# Esempio di utilizzo\n",
    "idrunn = 1\n",
    "plog(\"PLOAD_DIP\", \"Inizio procedura\", idrunn)\n",
    "plog(\"PLOAD_DIP\", \"Righe inserite in DIP00_OK: 25\", idrunn)\n",
    "plog(\"PLOAD_DIP\", \"Fine procedura\", idrunn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "73fbb060-f351-41cf-b0bd-69ea99692655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---------+------------------------------------+-------------------+\n",
      "|IDRUN|IDTLOG|CALLER   |TESTO                               |DINS               |\n",
      "+-----+------+---------+------------------------------------+-------------------+\n",
      "|1    |1     |PLOAD_DIP|INIZIO PROCEDURA                    |2025-09-25 14:09:21|\n",
      "|1    |2     |PLOAD_DIP|RIGHE INSERITE IN DIP00_OK: 25      |2025-09-25 14:09:21|\n",
      "|1    |3     |PLOAD_DIP|FINE PROCEDURA                      |2025-09-25 14:09:21|\n",
      "|1    |4     |PLOAD_DIP|INIZIO PROCEDURA                    |2025-09-25 14:16:29|\n",
      "|1    |5     |PLOAD_DIP|TABELLE DIP00_OK E DIP00_KO TRONCATE|2025-09-25 14:16:29|\n",
      "|1    |6     |PLOAD_DIP|RIGHE INSERITE IN DIP00_OK: 8       |2025-09-25 14:16:29|\n",
      "|1    |7     |PLOAD_DIP|RIGHE INSERITE IN DIP00_KO: 14      |2025-09-25 14:16:29|\n",
      "|1    |8     |PLOAD_DIP|FINE PROCEDURA                      |2025-09-25 14:16:29|\n",
      "|1    |9     |PLOAD_DIP|INIZIO PROCEDURA                    |2025-09-25 14:24:05|\n",
      "|1    |10    |PLOAD_DIP|TABELLE DIP00_OK E DIP00_KO TRONCATE|2025-09-25 14:24:05|\n",
      "|1    |11    |PLOAD_DIP|RIGHE INSERITE IN DIP00_OK: 7       |2025-09-25 14:24:05|\n",
      "|1    |12    |PLOAD_DIP|RIGHE INSERITE IN DIP00_KO: 15      |2025-09-25 14:24:05|\n",
      "|1    |13    |PLOAD_DIP|FINE PROCEDURA                      |2025-09-25 14:24:05|\n",
      "|1    |1     |PLOAD_DIP|INIZIO PROCEDURA                    |2025-09-25 14:27:35|\n",
      "|1    |2     |PLOAD_DIP|RIGHE INSERITE IN DIP00_OK: 25      |2025-09-25 14:27:35|\n",
      "|1    |3     |PLOAD_DIP|FINE PROCEDURA                      |2025-09-25 14:27:35|\n",
      "+-----+------+---------+------------------------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "schema_log = StructType([\n",
    "    StructField(\"IDRUN\", IntegerType(), True),\n",
    "    StructField(\"IDTLOG\", IntegerType(), True),\n",
    "    StructField(\"CALLER\", StringType(), True),\n",
    "    StructField(\"TESTO\", StringType(), True),\n",
    "    StructField(\"DINS\", StringType(), True)  # o TimestampType() se vuoi convertirlo subito\n",
    "])\n",
    "df_log = spark.read.csv(\"tlog.csv\", header=True, schema=schema_log)\n",
    "df_log.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c0ab7244-9b19-4d5c-b0a5-147c000bcbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def is_valid_row(row):\n",
    "    # SALARIO numerico e positivo\n",
    "    try:\n",
    "        salario = float(row['SALARIO'])\n",
    "        if salario <= 0:\n",
    "            return False\n",
    "    except (ValueError, TypeError):\n",
    "        return False\n",
    "\n",
    "    # DN formato YYYY-MM-DD\n",
    "    if not row['DN'] or not re.match(r'^\\d{4}-\\d{2}-\\d{2}$', row['DN']):\n",
    "        return False\n",
    "\n",
    "    # NOME non vuoto e senza numeri\n",
    "    if not row['NOME'] or re.search(r'\\d', row['NOME']):\n",
    "        return False\n",
    "\n",
    "    # Controllo giorno e mese validi\n",
    "    month = int(row['DN'][5:7])\n",
    "    day = int(row['DN'][8:10])\n",
    "    if month < 1 or month > 12 or day < 1 or day > 31:\n",
    "        return False\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5a51e5e7-b16b-4335-b8ac-ad782a8f12f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dip(df_raw, idrun, log_func):\n",
    "    dip_ok_file = 'DIP00_OK.csv'\n",
    "    dip_ko_file = 'DIP00_KO.csv'\n",
    "    \n",
    "    # Svuoto i file se esistono\n",
    "    for f in [dip_ok_file, dip_ko_file]:\n",
    "        with open(f, 'w', newline='') as fh:\n",
    "            writer = csv.writer(fh)\n",
    "            writer.writerow(['IDRUN','CF','NOME','DN','SALARIO','DINS'])\n",
    "    \n",
    "    log_func('PLOAD_DIP', 'Tabelle DIP00_OK e DIP00_KO troncate', idrun)\n",
    "    \n",
    "    count_ok = 0\n",
    "    count_ko = 0\n",
    "    for row in df_raw.collect():\n",
    "        row_dict = row.asDict()\n",
    "        row_dict['DINS'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        # Filtra dati validi\n",
    "        if is_valid_row(row_dict):\n",
    "            with open(dip_ok_file, 'a', newline='') as f_ok:\n",
    "                writer = csv.writer(f_ok)\n",
    "                writer.writerow([idrunn, row_dict['CF'], row_dict['NOME'], row_dict['DN'], row_dict['SALARIO'], row_dict['DINS']])\n",
    "            count_ok += 1\n",
    "        else:\n",
    "            with open(dip_ko_file, 'a', newline='') as f_ko:\n",
    "                writer = csv.writer(f_ko)\n",
    "                writer.writerow([idrunn, row_dict['CF'], row_dict['NOME'], row_dict['DN'], row_dict['SALARIO'], row_dict['DINS']])\n",
    "            count_ko += 1\n",
    "    \n",
    "    log_func('PLOAD_DIP', f'Righe inserite in DIP00_OK: {count_ok}', idrun)\n",
    "    log_func('PLOAD_DIP', f'Righe inserite in DIP00_KO: {count_ko}', idrun)\n",
    "    log_func('PLOAD_DIP', 'Fine procedura', idrun)\n",
    "    \n",
    "    return dip_ok_file, dip_ko_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b0656c2d-8620-49b0-9741-21a8fcd73f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dip_ok_file, dip_ko_file = load_dip(df_raw, idrunn, plog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5f7b37de-02a7-4885-8c76-eb27263c490f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DIP_OK ===\n",
      "+-----+----------------+--------------+----------+-------+-------------------+\n",
      "|IDRUN|CF              |NOME          |DN        |SALARIO|DINS               |\n",
      "+-----+----------------+--------------+----------+-------+-------------------+\n",
      "|1    |RSSMRA85M01H501Z|Mario Rossi   |1985-03-15|2500   |2025-09-25 15:00:20|\n",
      "|1    |BNCLGU90B22F205X|Luca Bianchi  |1990-07-22|3200   |2025-09-25 15:00:20|\n",
      "|1    |NGRMRT75D10E345W|Martina Neri  |1975-12-10|3100   |2025-09-25 15:00:20|\n",
      "|1    |FBLGPP88A12H501V|Filippo Baldi |1988-01-12|2700   |2025-09-25 15:00:20|\n",
      "|1    |GRLFRN83B25H501S|Giorgia Ferri |1983-02-25|2900   |2025-09-25 15:00:20|\n",
      "|1    |PPLGRD91D05E345Q|Paolo Pugliese|1991-05-05|3400   |2025-09-25 15:00:20|\n",
      "|1    |NGRMRT75D10E345W|Maria Santa   |1975-10-10|3100   |2025-09-25 15:00:20|\n",
      "+-----+----------------+--------------+----------+-------+-------------------+\n",
      "\n",
      "=== DIP_KO ===\n",
      "+-----+---------------------------------+-----------------+-----------+-------+-------------------+\n",
      "|IDRUN|CF                               |NOME             |DN         |SALARIO|DINS               |\n",
      "+-----+---------------------------------+-----------------+-----------+-------+-------------------+\n",
      "|1    |RSSMRA85M01H501Z                 |Mario Rossi      |1985-03-15 |-2500  |2025-09-25 15:00:20|\n",
      "|1    |VRDLCN80C15D612Y                 |Claudia Verdi    |15/08/1980 |2800   |2025-09-25 15:00:20|\n",
      "|1    |DMRCNZ92E18F205U                 |Daniele Moroni   |1992-06-188|3000   |2025-09-25 15:00:20|\n",
      "|1    |SPRTMN7820G345T                  |Simone Sportiello|1978-20-20 |-500   |2025-09-25 15:00:20|\n",
      "|1    |CNCLNZ87C30D612R                 |Concetta Lanza   |30-06-1987 |NULL   |2025-09-25 15:00:20|\n",
      "|1    |LDDRCR99R14F205U                 |Riccardo Loddo   |1999-14-04 |2000   |2025-09-25 15:00:20|\n",
      "|1    |LDDRCR99R14F205U                 |Riccardo Pippo   |1999-04-14 |NULL   |2025-09-25 15:00:20|\n",
      "|1    |NGRMRT75D10E345W                 |Ma3t1na Polgatti |1975-10-10 |3100   |2025-09-25 15:00:20|\n",
      "|1    |NGRMRT75345W                     |Maria Santa1     |1975-??-10 |3100   |2025-09-25 15:00:20|\n",
      "|1    |NGRMRT75345W                     |Maria Santa2     |1975-10-10 |-100   |2025-09-25 15:00:20|\n",
      "|1    |NGRMRT75345W                     |Maria Santa3     |1975-10-10 |200    |2025-09-25 15:00:20|\n",
      "|1    |ABCD1234EF567890                 |Z0l0 Rossi       |1980-13-01 |1500   |2025-09-25 15:00:20|\n",
      "|1    |LMNOPQ12RST345678                |Giulia1 Bianchi  |1990-02-30 |2800   |2025-09-25 15:00:20|\n",
      "|1    |QRSTUV98XYZ123456Alessandro Verdi|1995-11-31       |abc        |NULL   |2025-09-25 15:00:20|\n",
      "|1    |WXYZ1234ABCD56789                |Federica Rossi   |1992-00-12 |0      |2025-09-25 15:00:20|\n",
      "+-----+---------------------------------+-----------------+-----------+-------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, IntegerType, DateType, TimestampType\n",
    "\n",
    "# Schema per i file dip_ok / dip_ko\n",
    "schema_result = StructType([\n",
    "    StructField(\"IDRUN\", IntegerType(), True),\n",
    "    StructField(\"CF\", StringType(), True),\n",
    "    StructField(\"NOME\", StringType(), True),\n",
    "    StructField(\"DN\", StringType(), True),             # lo lasciamo stringa, poi puoi convertirlo\n",
    "    StructField(\"SALARIO\", IntegerType(), True),        # stessa logica, castabile dopo\n",
    "    StructField(\"DINS\", StringType(), True)            # o TimestampType se preferisci\n",
    "])\n",
    "\n",
    "\n",
    "# Leggo il file degli OK\n",
    "df_ok = spark.read.csv(\n",
    "    \"dip00_ok.csv\",\n",
    "    header=True,\n",
    "    schema=schema_result\n",
    ")\n",
    "\n",
    "# Leggo il file degli KO\n",
    "df_ko = spark.read.csv(\n",
    "    \"dip00_ko.csv\",\n",
    "    header=True,\n",
    "    schema=schema_result\n",
    ")\n",
    "\n",
    "# Mostro le due \"tabelle\"\n",
    "print(\"=== DIP_OK ===\")\n",
    "df_ok.show(truncate=False)\n",
    "\n",
    "print(\"=== DIP_KO ===\")\n",
    "df_ko.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "49d4f2b5-240d-4b29-b209-0333b23fe790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------------+--------------+----------+-------+-------------------+\n",
      "|IDRUN|              CF|          NOME|        DN|SALARIO|               DINS|\n",
      "+-----+----------------+--------------+----------+-------+-------------------+\n",
      "|    1|BNCLGU90B22F205X|  Luca Bianchi|1990-07-22|   3200|2025-09-25 15:00:20|\n",
      "|    1|NGRMRT75D10E345W|  Martina Neri|1975-12-10|   3100|2025-09-25 15:00:20|\n",
      "|    1|PPLGRD91D05E345Q|Paolo Pugliese|1991-05-05|   3400|2025-09-25 15:00:20|\n",
      "|    1|NGRMRT75D10E345W|   Maria Santa|1975-10-10|   3100|2025-09-25 15:00:20|\n",
      "+-----+----------------+--------------+----------+-------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_filtrato = df_ok.filter(col(\"SALARIO\") > 3000)\n",
    "df_filtrato.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8164a54d-ea97-474c-bfc8-2c673e913d58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
